"""
ThinkPRM Confidence Score Generation Script (OpenAI Ver.)

thinkprm_data.jsonì˜ ê° ê²€ì¦ ìŠ¤í…ì— confidence scoreë¥¼ ì¶”ê°€í•˜ì—¬
thinkprm_data_conf.jsonì„ ìƒì„±í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
1. OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
   export OPENAI_API_KEY='your_api_key_here'

2. í„°ë¯¸ë„ì—ì„œ ì´ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:
   python add_conf.py
"""

import json
import os
import sys
import re
import openai  # SGLang ëŒ€ì‹  OpenAI ì„í¬íŠ¸
from tqdm import tqdm
import traceback

# ============================================================================
# ì„¤ì •
# ============================================================================
# SGLANG_ENDPOINT = "http://127.0.0.1:31111" # SGLang ì œê±°
# MODEL_NAME_OR_PATH = "KirillR/QwQ-32B-Preview-AWQ" # ë¡œì»¬ ëª¨ë¸ ì œê±°

# OpenAI ì„¤ì • ì¶”ê°€
# OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
OPENAI_API_KEY = ""
OPENAI_MODEL_NAME = "gpt-5-nano" # ìš”ì²­í•˜ì‹  ëª¨ë¸ëª…

N_SAMPLES_PER_STEP = 10  # ê° ìŠ¤í…ë‹¹ ìƒì„±í•  ê²€ì¦ CoT ê°œìˆ˜
MAX_GENERATION_TOKENS = 2048
INPUT_FILENAME = "thinkprm_data.json"
OUTPUT_FILENAME = "thinkprm_data_conf.json"
DEBUG_LOG_FILENAME = "add_conf_debug.log"

# SGLangì˜ stop_patternsë¥¼ ìƒìˆ˜ë¡œ ì´ë™
STOP_PATTERNS = [
    "\n\nStep ",  # ë‹¤ìŒ ìŠ¤í…ì´ ì‹œì‘ë˜ë©´ ì¤‘ë‹¨
    "<|im_end|>",
    "</s>",
    "</think>"
]

# ============================================================================
# ë¡œê¹… í•¨ìˆ˜
# ============================================================================

log_file = None

def log(message):
    """ì½˜ì†”ê³¼ íŒŒì¼ì— ë™ì‹œ ì¶œë ¥"""
    print(message)
    if log_file:
        log_file.write(message + "\n")
        log_file.flush()

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

def is_verification_chunk(chunk):
    """ê²€ì¦ ì²­í¬ì¸ì§€ í™•ì¸ (Step k:ë¡œ ì‹œì‘í•˜ê³  \\boxed{}ë¡œ ëë‚˜ëŠ”ì§€)"""
    chunk = chunk.strip()
    if not chunk.startswith("Step"):
        return False
    if "\\boxed{" not in chunk:
        return False
    return True

def get_prefix_steps_until(prefix_steps, step_index):
    """
    step_indexë²ˆì§¸ ìŠ¤í…ê¹Œì§€ì˜ prefix_stepsë§Œ ë°˜í™˜
    
    Args:
        prefix_steps: ì „ì²´ prefix_steps ë¦¬ìŠ¤íŠ¸
        step_index: í¬í•¨í•˜ê³  ì‹¶ì€ ë§ˆì§€ë§‰ ìŠ¤í… ì¸ë±ìŠ¤ (0-based)
    
    Returns:
        step_indexë²ˆì§¸ ìŠ¤í…ê¹Œì§€ì˜ prefix_stepsë¥¼ '\n'ìœ¼ë¡œ ê²°í•©í•œ ë¬¸ìì—´
    """
    # step_indexëŠ” 0-basedì´ë¯€ë¡œ, step_index+1ê°œê¹Œì§€ í¬í•¨
    selected_steps = prefix_steps[:step_index + 1]
    return '\n'.join(selected_steps)

def get_prefix_before_step(cot_chunks, step_index):
    """
    step_indexë²ˆì§¸ ê²€ì¦ ì²­í¬ ì§ì „ê¹Œì§€ì˜ ê²€ì¦ ì²­í¬ë“¤ë§Œ ì—°ê²°
    ë‹¨, ë§¨ ì•ì˜ "<think>\n"ì€ í¬í•¨í•˜ë˜, ì²« ê²€ì¦ ì²­í¬ ì´ì „ì˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì œì™¸
    
    Args:
        cot_chunks: ì „ì²´ cot_chunks ë¦¬ìŠ¤íŠ¸
        step_index: ê²€ì¦í•˜ë ¤ëŠ” ìŠ¤í…ì˜ ì¸ë±ìŠ¤ (0-based)
    
    Returns:
        "<think>\n" + ê²€ì¦ ì²­í¬ë“¤ë§Œ ì—°ê²°í•œ ë¬¸ìì—´
    """
    prefix_chunks = []
    verification_count = 0
    first_verification_found = False
    
    for chunk in cot_chunks:
        if is_verification_chunk(chunk):
            # ì²« ë²ˆì§¸ ê²€ì¦ ì²­í¬ë¥¼ ë°œê²¬í•œ ìˆœê°„ë¶€í„° ìˆ˜ì§‘ ì‹œì‘
            first_verification_found = True
            
            if verification_count == step_index:
                # ëª©í‘œ ê²€ì¦ ì²­í¬ì— ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨
                break
            verification_count += 1
            prefix_chunks.append(chunk)
        elif first_verification_found:
            # ì²« ê²€ì¦ ì²­í¬ ë°œê²¬ ì´í›„ì˜ í…ìŠ¤íŠ¸ë§Œ ìˆ˜ì§‘ (ì²­í¬ ì‚¬ì´ì˜ "\n\n" ë“±)
            prefix_chunks.append(chunk)
    
    # ë§¨ ì•ì— "<think>\n" ì¶”ê°€
    return "<think>\n" + ''.join(prefix_chunks)

def extract_boxed_label(text):
    """ìƒì„±ëœ í…ìŠ¤íŠ¸ì—ì„œ \\boxed{correct} ë˜ëŠ” \\boxed{incorrect} ì¶”ì¶œ"""
    pattern = r'\\boxed\{(correct|incorrect)\}'
    match = re.search(pattern, text, re.IGNORECASE)
    
    if match:
        label = match.group(1).lower()
        return 1 if label == "correct" else 0
    return None

def format_verification_prompt(problem, prefix_steps_until_current, cot_prefix, current_step_number):
    """
    OpenAI APIì— ë§ëŠ” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„± (ìˆ˜ì •ëœ ë²„ì „)
    
    Args:
        problem: ìˆ˜í•™ ë¬¸ì œ
        prefix_steps_until_current: í˜„ì¬ ê²€ì¦í•  ìŠ¤í…ê¹Œì§€ì˜ í’€ì´ ê³¼ì •
        cot_prefix: ì´ì „ ê²€ì¦ ì²­í¬ë“¤ (ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©)
        current_step_number: í˜„ì¬ ê²€ì¦í•  ìŠ¤í… ë²ˆí˜¸ (1-based)
    """
    
    # ì´ì „ ê²€ì¦ ë‚´ìš©(cot_prefix)ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ê°€ê³µ
    previous_verifications_text = ""
    if cot_prefix == "<think>\n":
        # Step 1ì„ ê²€ì¦í•  ì°¨ë¡€ (ì´ì „ ê²€ì¦ ë‚´ìš© ì—†ìŒ)
        previous_verifications_text = "You have not verified any steps yet."
    else:
        # Step 2 ì´ìƒì¼ ê²½ìš°, <think> íƒœê·¸ë¥¼ ì œì™¸í•œ ë‚´ìš©ë§Œ ì¶”ì¶œ
        previous_verifications_text = cot_prefix[8:].strip()
        
    
    # ìƒˆ ì§€ì‹œì‚¬í•­ì´ í¬í•¨ëœ User í”„ë¡¬í”„íŠ¸
    user_content = f"""[Problem]
{problem}

[Solution Steps]
{prefix_steps_until_current}

[Previous Verifications]
Below are the verifications you have already completed.
{previous_verifications_text}

[Your Task]
You must now verify **ONLY Step {current_step_number}**.
Provide a brief critique for Step {current_step_number} and then conclude with EXACTLY one of:
- The step is \\boxed{{correct}} (if the step is correct)
- The step is \\boxed{{incorrect}} if the step contains an error)

Do not repeat verifications for previous steps.

Output:"""

    messages = [
        {
            "role": "system",
            "content": "You are a mathematical reasoning verification assistant."
        },
        {
            "role": "user",
            "content": user_content
        },
        {
            "role": "assistant",
            "content": "<think>\n" # ëª¨ë¸ì´ CoTë¥¼ ì‹œì‘í•˜ë„ë¡ ìœ ë„
        }
    ]
    
    return messages

# ============================================================================
# SGLang ìƒì„± í•¨ìˆ˜ (ì œê±°)
# ============================================================================
# prompt_to_states = {}
# @function
# def generate_step_verification(s, prompt: str, n: int):
# ... (SGLang í•¨ìˆ˜ ì „ì²´ ì œê±°)

# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================================

def main():
    global log_file
    
    # ë¡œê·¸ íŒŒì¼ ì—´ê¸°
    log_file = open(DEBUG_LOG_FILENAME, 'w', encoding='utf-8')
    
    log("=" * 70)
    log("ThinkPRM Confidence Score Generation (OpenAI Ver.)")
    log("=" * 70)
    
    # 1. OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    log(f"\n[1/5] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
    
    if not OPENAI_API_KEY:
        log("    âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        log_file.close()
        return 1
    
    try:
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        log(f"    âœ“ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ (Model: {OPENAI_MODEL_NAME})")
    except Exception as e:
        log(f"    âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        log_file.close()
        return 1

    # 2. í† í¬ë‚˜ì´ì € ë¡œë“œ (ì œê±°)
    # log(f"\n[2/5] í† í¬ë‚˜ì´ì € ë¡œë“œ ì¤‘...")
    
    # 3. ì…ë ¥ ë°ì´í„° ë¡œë“œ (ì„¹ì…˜ ë²ˆí˜¸ ë³€ê²½ [2/5])
    log(f"\n[2/5] ì…ë ¥ ë°ì´í„° ë¡œë“œ ì¤‘...")
    log(f"    íŒŒì¼: {INPUT_FILENAME}")
    
    try:
        with open(INPUT_FILENAME, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        data = data[:10]
        
        log(f"    âœ“ ë¡œë“œ ì„±ê³µ: {len(data):,}ê°œ ë¬¸ì œ")
        
        total_steps_to_verify = sum(item['valid_prefix_step_count'] for item in data)
        total_api_calls = total_steps_to_verify * N_SAMPLES_PER_STEP
        log(f"    - ê²€ì¦í•  ì´ ìŠ¤í… ìˆ˜: {total_steps_to_verify:,}ê°œ")
        log(f"    - ì˜ˆìƒ API í˜¸ì¶œ íšŸìˆ˜: {total_api_calls:,}íšŒ (ìŠ¤í…ë‹¹ {N_SAMPLES_PER_STEP}íšŒ)")
        
    except Exception as e:
        log(f"    âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
        log_file.close()
        return 1

    # 4. Confidence Score ìƒì„± (ì„¹ì…˜ ë²ˆí˜¸ ë³€ê²½ [3/5])
    log(f"\n[3/5] Confidence Score ìƒì„± ì¤‘...")
    log(f"    - ë¬¸ì œ ìˆ˜: {len(data)}")
    log(f"    - ìŠ¤í…ë‹¹ ìƒ˜í”Œë§ íšŸìˆ˜: {N_SAMPLES_PER_STEP}\n")
    
    result_data = []
    total_steps_processed = 0
    n_skipped = 0
    
    for problem_idx, item in enumerate(tqdm(data, desc="ë¬¸ì œ ì²˜ë¦¬ ì¤‘")):
        try:
            problem = item['problem']
            prefix = item['prefix']
            prefix_steps = item['prefix_steps']
            cot_chunks = item['cot_chunks']
            gt_step_labels = item['gt_step_labels']
            valid_prefix_step_count = item['valid_prefix_step_count']
            
            log(f"\n{'=' * 70}")
            log(f"ë¬¸ì œ {problem_idx}")
            log(f"{'=' * 70}")
            log(f"ë¬¸ì œ í…ìŠ¤íŠ¸:\n{problem}")
            log(f"\nvalid_prefix_step_count: {valid_prefix_step_count}")
            log(f"gt_step_labels: {gt_step_labels}")
            
            # ì—…ë°ì´íŠ¸í•  cot_chunks ë³µì‚¬
            updated_cot_chunks = cot_chunks.copy()
            
            # valid_prefix_step_countë§Œí¼ë§Œ ì²˜ë¦¬
            for step_idx in range(valid_prefix_step_count):
                log(f"\n{'-' * 70}")
                log(f"Step {step_idx + 1} ì²˜ë¦¬ ì‹œì‘")
                log(f"{'-' * 70}")
                
                # í˜„ì¬ ìŠ¤í…ê¹Œì§€ì˜ prefix_steps ê°€ì ¸ì˜¤ê¸°
                prefix_steps_until_current = get_prefix_steps_until(prefix_steps, step_idx)
                
                log(f"\n=== Prefix Steps (Step {step_idx + 1}ê¹Œì§€) ===")
                log(prefix_steps_until_current)
                log(f"=== Prefix Steps ë ===\n")
                
                # í•´ë‹¹ ìŠ¤í… ì§ì „ê¹Œì§€ì˜ CoT í”„ë¦¬í”½ìŠ¤ ìƒì„±
                cot_prefix = get_prefix_before_step(cot_chunks, step_idx)
                
                log(f"\n=== CoT Prefix (Step {step_idx}ê¹Œì§€ ê²€ì¦) ===")
                log(cot_prefix)
                log(f"=== CoT Prefix ë (ê¸¸ì´: {len(cot_prefix)} ë¬¸ì) ===\n")
                
                # í”„ë¡¬í”„íŠ¸ ìƒì„± (OpenAI API í˜•ì‹)
                messages = format_verification_prompt(
                    problem=problem,
                    prefix_steps_until_current=prefix_steps_until_current,
                    cot_prefix=cot_prefix,
                    current_step_number=(step_idx + 1)  # ğŸ‘ˆ ì´ ì¤„ ì¶”ê°€
                )
                
                log(f"API ìš”ì²­ ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ\n")
                
                # prompt_to_states ì´ˆê¸°í™” (ì œê±°)
                # global prompt_to_states
                # prompt_to_states = {}
                
                # N_SAMPLES_PER_STEPë²ˆ ìƒì„± (10ë²ˆ ê°œë³„ í˜¸ì¶œ)
                log(f"API ìš”ì²­ ì‹œì‘ (ì´ {N_SAMPLES_PER_STEP}ë²ˆ ê°œë³„ í˜¸ì¶œ)...\n")
                
                generated_verifications = []
                
                for i in range(N_SAMPLES_PER_STEP):
                    log(f"    -> ìƒ˜í”Œ {i + 1}/{N_SAMPLES_PER_STEP} ìš”ì²­ ì¤‘...")
                    
                    try:
                        response = client.chat.completions.create(
                            model=OPENAI_MODEL_NAME,
                            messages=messages,
                            max_completion_tokens=MAX_GENERATION_TOKENS,
                            temperature=1.0,
                            #stop=STOP_PATTERNS,
                            n=1  # ğŸ‘ˆ í•œ ë²ˆì— 1ê°œë§Œ ìš”ì²­
                        )
                        
                        # ìƒì„±ëœ ê²°ê³¼ ìˆ˜ì§‘
                        verification = response.choices[0].message.content
                        generated_verifications.append(verification.strip())
                    
                    except Exception as api_err:
                        log(f"    âŒ ìƒ˜í”Œ {i + 1} ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {api_err}")
                        log(f"    âš ï¸ í•´ë‹¹ ìƒ˜í”Œì€ ê±´ë„ˆëœë‹ˆë‹¤.")
                        # ì´ ìƒ˜í”Œì€ ê±´ë„ˆë›°ê³  ë‹¤ìŒ ë£¨í”„ ê³„ì† ì§„í–‰
                        continue 
                
                log(f"\nì´ {len(generated_verifications)}/{N_SAMPLES_PER_STEP}ê°œ ìƒ˜í”Œ ìˆ˜ì§‘ ì™„ë£Œ.")
                
                # GT ë¼ë²¨ê³¼ ë¹„êµ
                gt_label = gt_step_labels[step_idx]
                gt_numeric = 1 if gt_label == '+' else 0
                
                log(f"GT ë¼ë²¨: {gt_label} ({gt_numeric})\n")
                log(f"{'=' * 70}")
                log(f"=== ìƒì„±ëœ ê²€ì¦ë“¤ ===")
                log(f"{'=' * 70}")
                
                # ê° ìƒì„± ê²°ê³¼ì—ì„œ ë¼ë²¨ ì¶”ì¶œ
                predicted_labels = []
                for i, gen_text in enumerate(generated_verifications):
                    log(f"\n[ìƒ˜í”Œ {i+1}]")
                    log("-" * 70)
                    log(gen_text)
                    log("-" * 70)
                    
                    pred_label = extract_boxed_label(gen_text)
                    predicted_labels.append(pred_label)
                    log(f"ì¶”ì¶œëœ ë¼ë²¨: {pred_label} ({'correct' if pred_label == 1 else 'incorrect' if pred_label == 0 else 'PARSE_FAILED'})")
                
                # Confidence ê³„ì‚° (ì¼ì¹˜ ë¹„ìœ¨)
                valid_predictions = [p for p in predicted_labels if p is not None]
                
                log(f"\n{'=' * 70}")
                log(f"=== ê²°ê³¼ ë¶„ì„ ===")
                log(f"{'=' * 70}")
                
                if len(valid_predictions) > 0:
                    matches = sum(1 for pred in valid_predictions if pred == gt_numeric)
                    confidence = matches / len(valid_predictions)
                    log(f"ì´ ìƒì„±: {len(predicted_labels)}ê°œ")
                    log(f"íŒŒì‹± ì„±ê³µ: {len(valid_predictions)}ê°œ")
                    log(f"GTì™€ ì¼ì¹˜: {matches}ê°œ")
                    log(f"Confidence: {confidence:.2f}")
                else:
                    confidence = 0.0
                    log(f"âš ï¸ íŒŒì‹± ì„±ê³µí•œ ì˜ˆì¸¡ ì—†ìŒ!")
                
                # í•´ë‹¹ ê²€ì¦ ì²­í¬ì— confidence íƒœê·¸ ì¶”ê°€
                verification_count = 0
                chunk_found = False
                for chunk_idx, chunk in enumerate(updated_cot_chunks):
                    if is_verification_chunk(chunk):
                        if verification_count == step_idx:
                            log(f"\nê²€ì¦ ì²­í¬ ì°¾ìŒ (cot_chunks ì¸ë±ìŠ¤: {chunk_idx})")
                            log(f"=== ì›ë³¸ ì²­í¬ ===")
                            log(chunk)
                            log(f"=== ì›ë³¸ ì²­í¬ ë ===")
                            
                            updated_cot_chunks[chunk_idx] = chunk + f"<confidence>{confidence:.2f}</confidence>"
                            
                            log(f"\n=== ì—…ë°ì´íŠ¸ëœ ì²­í¬ ===")
                            log(updated_cot_chunks[chunk_idx])
                            log(f"=== ì—…ë°ì´íŠ¸ëœ ì²­í¬ ë ===")
                            
                            chunk_found = True
                            break
                        verification_count += 1
                
                if not chunk_found:
                    log(f"\nâš ï¸ ê²€ì¦ ì²­í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ!")
                
                total_steps_processed += 1
                log(f"\nStep {step_idx + 1} ì²˜ë¦¬ ì™„ë£Œ!\n")
            
            # ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ì €ì¥
            updated_item = item.copy()
            updated_item['cot_chunks'] = updated_cot_chunks
            # cotë„ ì—…ë°ì´íŠ¸ (ëª¨ë“  ì²­í¬ í•©ì¹˜ê¸°)
            updated_item['cot'] = ''.join(updated_cot_chunks)
            result_data.append(updated_item)
            
            log(f"\n{'=' * 70}")
            log(f"ë¬¸ì œ {problem_idx} ì²˜ë¦¬ ì™„ë£Œ!")
            log(f"{'=' * 70}\n")
            
        except Exception as e:
            log(f"\nâš ï¸  ë¬¸ì œ {problem_idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            log(traceback.format_exc())
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ë°ì´í„° ê·¸ëŒ€ë¡œ ì¶”ê°€
            result_data.append(item)
            n_skipped += 1
            continue
    
    # 5. ê²°ê³¼ ì €ì¥ (ì„¹ì…˜ ë²ˆí˜¸ ë³€ê²½ [4/5])
    log(f"\n[4/5] ê²°ê³¼ ì €ì¥ ì¤‘...")
    
    if not result_data:
        log("    âŒ ìƒì„±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        log_file.close()
        return 1
    
    try:
        with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, indent=2, ensure_ascii=False)
        
        log(f"    âœ“ ì €ì¥ ì™„ë£Œ: {OUTPUT_FILENAME}")
        log("\n" + "=" * 70)
        log("ìƒì„± ì™„ë£Œ!")
        log("=" * 70)
        log(f"ì²˜ë¦¬ëœ ë¬¸ì œ ìˆ˜:     {len(result_data):,}ê°œ")
        log(f"ê±´ë„ˆë›´ ë¬¸ì œ ìˆ˜:     {n_skipped:,}ê°œ")
        log(f"ì²˜ë¦¬ëœ ìŠ¤í… ìˆ˜:     {total_steps_processed:,}ê°œ")
        log("=" * 70)
        log(f"\në””ë²„ê·¸ ë¡œê·¸: {DEBUG_LOG_FILENAME}")
        
        log_file.close()
        return 0
        
    except Exception as e:
        log(f"    âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        log(traceback.format_exc())
        log_file.close()
        return 1

if __name__ == "__main__":
    exit_code = main()
    
    print("ì •ë¦¬ ì¤‘...")
    os._exit(exit_code)