"""
ThinkPRM Confidence Score Generation Script (Final Fixed Prompt Ver.)
- Terminal: Shows ONLY progress bar (tqdm)
- Log File: Records EVERYTHING (Detailed samples, prompt, parsing results)
- Prompt: RESTORED to original requested version (Exact Match)
"""

import json
import os
import sys
import re
import traceback
import argparse
from transformers import AutoTokenizer
from sglang import function, gen, set_default_backend, RuntimeEndpoint
from tqdm import tqdm

# ============================================================================
# [ê¸°ë³¸ ì„¤ì •ê°’]
# ============================================================================
DEFAULT_SGLANG_ENDPOINT = "http://127.0.0.1:31111"
DEFAULT_MODEL_PATH = "KirillR/QwQ-32B-Preview-AWQ"
DEFAULT_N_SAMPLES = 10
DEFAULT_MAX_TOKENS = 4096
DEFAULT_INPUT_FILE = "thinkprm_data.json"
DEFAULT_OUTPUT_FILE = "thinkprm_data_conf.json"
DEFAULT_LOG_FILE = "add_conf_debug.log"
DEFAULT_TEMPERATURE = 1.0
DEFAULT_SAVE_INTERVAL = 10

# ì „ì—­ ë³€ìˆ˜ (argsë¡œ ë®ì–´ì”Œì›Œì§)
SGLANG_ENDPOINT = DEFAULT_SGLANG_ENDPOINT
MODEL_NAME_OR_PATH = DEFAULT_MODEL_PATH
N_SAMPLES_PER_STEP = DEFAULT_N_SAMPLES
MAX_GENERATION_TOKENS = DEFAULT_MAX_TOKENS
TEMPERATURE = DEFAULT_TEMPERATURE
DEBUG_LOG_FILENAME = DEFAULT_LOG_FILE

# ============================================================================
# ë¡œê¹… í•¨ìˆ˜
# ============================================================================
log_file = None

def log(message, console=False):
    """
    console=False: íŒŒì¼ì—ë§Œ ê¸°ë¡ (tqdm ì§„í–‰ë°” ë³´í˜¸)
    console=True: íŒŒì¼+ì½˜ì†” ë‘˜ ë‹¤ ì¶œë ¥ (ì—ëŸ¬, ì‹œì‘ ë©”ì‹œì§€ ë“±)
    """
    if console:
        print(message)
    
    if log_file:
        log_file.write(str(message) + "\n")
        log_file.flush()

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================
def is_verification_chunk(chunk):
    chunk = chunk.strip()
    if not chunk.startswith("Step"): return False
    if "\\boxed{" not in chunk: return False
    return True

def get_cot_prefix_before_step(cot_chunks, step_index):
    prefix_chunks = []
    verification_count = 0
    for chunk in cot_chunks[1:]:
        if is_verification_chunk(chunk):
            if verification_count == step_index: break
            verification_count += 1
        prefix_chunks.append(chunk)
    return ''.join(prefix_chunks)

def extract_step_verification(text, step_number):
    # Step N: ... \boxed{correct} í˜•ì‹ ì°¾ê¸°
    pattern = rf'Step {step_number}:.*?\\boxed\{{(correct|incorrect)\}}'
    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
    if match:
        return match.group(0), (1 if match.group(1).lower() == "correct" else 0)
    
    # ë§Œì•½ í˜•ì‹ì´ ê¹¨ì ¸ì„œ \boxed{correct}ë§Œ ìˆëŠ” ê²½ìš°
    pattern = r'\\boxed\{(correct|incorrect)\}'
    match = re.search(pattern, text, re.IGNORECASE)
    if match:
        return text, (1 if match.group(1).lower() == "correct" else 0)
    return None, None

def create_stop_sequence_after_boxed(text):
    pattern = r'(\\boxed\{(?:correct|incorrect)\})'
    match = re.search(pattern, text, re.IGNORECASE)
    if match:
        return text[:match.end()]
    return text

# â­ï¸ [ìˆ˜ì •ë¨] ìš”ì²­í•˜ì‹  í”„ë¡¬í”„íŠ¸ ì›ë³¸ ê·¸ëŒ€ë¡œ ì ìš©
def format_verification_prompt(problem, prefix, step_idx, cot_prefix):
    """
    SGLangì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„± (í•­ìƒ 9ê°œì˜ Few-shot ì˜ˆì‹œ í¬í•¨)
    """
   
    # ê¸°ë³¸ ì‚¬ìš©ì ì»¨í…ì¸ 
    user_content = f"""Problem:
{problem}

Solution:
{prefix}

CRITICAL INSTRUCTIONS - YOU MUST FOLLOW THESE EXACTLY:

You are a mathematical verification assistant. You MUST verify each step of the solution above.

FOR EACH STEP, YOU MUST:
1. Start with "Step N:" (e.g., "Step 1:", "Step 2:").
2. Provide a brief mathematical critique.
3. End with EXACTLY one of these two phrases:
   - Thus, the step is \\boxed{{correct}}. The evaluation for this step ends here.
   - Thus, the step is \\boxed{{incorrect}}. The evaluation for this step ends here.

IMPORTANT RULES:
- **ALL STEPS**: You MUST verify EVERY step, including the final "# Answer" step.
- **STEP 1**: Do NOT use markdown headers like "**Step 1:**". Just write "Step 1:" as plain text.
- **ANSWER STEP**: If the step involves "# Answer", check if the final value is mathematically consistent with previous steps. Do NOT output "N/A", "Conclusion", or "[Not a solution step]". Treat it exactly like any other step.
- **FORMAT**: Do NOT use square brackets like [boxed{{correct}}]. You MUST use LaTeX format: \\boxed{{correct}} or \\boxed{{incorrect}}.
- **ENDING**: You MUST use the exact closing phrase provided above. Do NOT just say "The answer is correct" or "The step is valid".
"""

    # -------------------------------------------------------------------------
    # Few-shot Examples (ì´ 9ê°œ: ì‹¤íŒ¨ ì‚¬ë¡€ 5ê°œ + ì„±ê³µ ì‚¬ë¡€ 4ê°œ)
    # -------------------------------------------------------------------------
    few_shot_examples = """
=== INCORRECT EXAMPLES (DO NOT DO THIS) ===

[Bad Example 1: Last step using value in box instead of correct/incorrect]
Problem: Calculate 3 + 4.
Solution:
Step 5: # Answer 7
Your answer:
Step 5: # Answer 7 Critique: The calculation 3+4=7 is correct. Thus, the step is \\boxed{7}. The evaluation for this step ends here.
(ERROR: The box must contain 'correct' or 'incorrect', not the number 7.)

[Bad Example 2: Last step missing the mandatory closing phrase]
Problem: Multiply 3 by 5.
Solution:
Step 4: # Answer 15
Your answer:
Step 4: # Answer 15 Critique: The final answer matches the derivation. The solution is correct.
(ERROR: Missing the mandatory phrase "Thus, the step is \\boxed{correct}. The evaluation for this step ends here.")

[Bad Example 3: Step 1 format violation]
Problem: Find the perimeter of a rectangle with width 5.
Solution:
Step 1: Let w be the width.
Your answer:
This step is correct because defining variables is a good start.
(ERROR: Must start with "Step 1:" and follow the full format.)

[Bad Example 4: Refusing to verify the Answer step]
Problem: What is 6 times 7?
Solution:
Step 6: # Answer 42
Your answer:
Step 6: # Answer 42 Critique: This is just the final answer format. [Not a solution step]
(ERROR: You must verify the answer step just like any other step.)

[Bad Example 5: Using N/A in the box]
Problem: Evaluate 2 + 5.
Solution:
Step 3: # Answer 7
Your answer:
Step 3: # Answer 7 Critique: There is no calculation here. Conclusion: \\boxed{N/A}
(ERROR: Never use N/A. If the number is correct based on previous steps, it is \\boxed{correct}.)

=== CORRECT EXAMPLES (FOLLOW THIS PATTERN) ===

[Good Example 1: Standard Step Verification]
Problem: Solve 3x = 12
Solution:
Step 1: Divide both sides by 3: x = 4.
Your answer:
Step 1: Divide both sides by 3: x = 4. Critique: Dividing both sides of 3x = 12 by 3 yields x = 4. The arithmetic is correct. Thus, the step is \\boxed{correct}. The evaluation for this step ends here.

[Good Example 2: Step 1 Verification (Clean Start)]
Problem: Find the area of a circle with radius 2.
Solution:
Step 1: The formula for area is $\\pi r^2$.
Your answer:
Step 1: The formula for area is $\\pi r^2$. Critique: The area of a circle is calculated using the formula $A = \\pi r^2$. This is the correct formula. Thus, the step is \\boxed{correct}. The evaluation for this step ends here.

[Good Example 3: Last Step (# Answer) Verification]
Problem: Calculate 10 - 2.
Solution:
Step 2: # Answer 8
Your answer:
Step 2: # Answer 8 Critique: The previous steps lead to 10 - 2. Since 10 - 2 = 8, the final answer provided is correct. Thus, the step is \\boxed{correct}. The evaluation for this step ends here.

[Good Example 4: Step 1 with existing context (Continuation)]
(Context provided: <think>Okay, let's verify step 1.\n)
Problem: Simplify 2a + 3a.
Solution:
Step 1: 2a + 3a = 5a.
Your answer:
Step 1: 2a + 3a = 5a. Critique: Combining like terms 2a and 3a results in 5a. This is algebraically correct. Thus, the step is \\boxed{correct}. The evaluation for this step ends here.
"""

    # í”„ë¡¬í”„íŠ¸ ì¡°í•© (í•­ìƒ Few-shot ì˜ˆì‹œ í¬í•¨)
    full_prompt = user_content + "\n\n" + few_shot_examples + "\n\n" + "Your answer:" + "\n\n" + cot_prefix
   
    return full_prompt

def print_full_prompt(prompt, step_num):
    log(f"\n{'='*80}\nPROMPT DETAILS - Step {step_num}\n{'='*80}\n{prompt}\n{'='*80}\n")

# ============================================================================
# SGLang ìƒì„± í•¨ìˆ˜
# ============================================================================
prompt_to_states = {}

@function
def generate_step_verification(s, prompt: str, num_samples: int):
    stop_patterns = ["The evaluation for this step ends here."]
    s += prompt
    forks = s.fork(num_samples)
    for fork in forks:
        fork += gen(
            "verification_output",
            max_tokens=MAX_GENERATION_TOKENS,
            temperature=TEMPERATURE,
            stop=stop_patterns,
        )
        if prompt not in prompt_to_states:
            prompt_to_states[prompt] = []
        prompt_to_states[prompt].append(fork)

# ============================================================================
# Argument Parser
# ============================================================================
def parse_arguments():
    parser = argparse.ArgumentParser(description="ThinkPRM Confidence Generation")
    parser.add_argument("--endpoint", type=str, default=DEFAULT_SGLANG_ENDPOINT)
    parser.add_argument("--model-path", type=str, default=DEFAULT_MODEL_PATH)
    parser.add_argument("--n-samples", type=int, default=DEFAULT_N_SAMPLES)
    parser.add_argument("--max-tokens", type=int, default=DEFAULT_MAX_TOKENS)
    parser.add_argument("--temperature", type=float, default=DEFAULT_TEMPERATURE)
    parser.add_argument("--input", type=str, default=DEFAULT_INPUT_FILE)
    parser.add_argument("--output", type=str, default=DEFAULT_OUTPUT_FILE)
    parser.add_argument("--log-file", type=str, default=DEFAULT_LOG_FILE)
    parser.add_argument("--save-interval", type=int, default=DEFAULT_SAVE_INTERVAL)
    parser.add_argument("--start", type=int, default=0)
    parser.add_argument("--end", type=int, default=-1)
    return parser.parse_args()

# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================================
def main():
    global log_file, SGLANG_ENDPOINT, MODEL_NAME_OR_PATH, N_SAMPLES_PER_STEP
    global MAX_GENERATION_TOKENS, TEMPERATURE, DEBUG_LOG_FILENAME, OUTPUT_FILENAME

    args = parse_arguments()
    
    # ìë™ íŒŒì¼ëª… ìƒì„±
    if args.output == DEFAULT_OUTPUT_FILE and (args.start != 0 or args.end != -1):
        base_name, ext = os.path.splitext(DEFAULT_OUTPUT_FILE)
        end_str = args.end if args.end != -1 else "end"
        args.output = f"{base_name}_{args.start}_{end_str}{ext}"
    
    SGLANG_ENDPOINT = args.endpoint
    MODEL_NAME_OR_PATH = args.model_path
    N_SAMPLES_PER_STEP = args.n_samples
    MAX_GENERATION_TOKENS = args.max_tokens
    TEMPERATURE = args.temperature
    DEBUG_LOG_FILENAME = args.log_file
    OUTPUT_FILENAME = args.output
    
    log_file = open(DEBUG_LOG_FILENAME, 'a', encoding='utf-8')
    
    # ì‹œì‘ ì •ë³´ëŠ” ì½˜ì†”ì—ë„ ì¶œë ¥
    log("=" * 70, console=True)
    log(f"ThinkPRM Confidence Generation (Started)", console=True)
    log("=" * 70, console=True)
    log(f" - Range: {args.start} ~ {'EOF' if args.end == -1 else args.end}", console=True)
    log(f" - Output: {OUTPUT_FILENAME}", console=True)
    log(f" - Log File: {DEBUG_LOG_FILENAME} (Details here)", console=True)

    try:
        set_default_backend(RuntimeEndpoint(SGLANG_ENDPOINT))
        log("âœ“ SGLang ì„œë²„ ì—°ê²° ì„±ê³µ", console=True)
    except Exception as e:
        log(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}", console=True)
        return 1

    try:
        with open(args.input, 'r', encoding='utf-8') as f:
            full_data = json.load(f)
            
        end_idx = args.end if args.end != -1 else len(full_data)
        result_data = []
        processed_count = 0
        
        if os.path.exists(OUTPUT_FILENAME):
            try:
                with open(OUTPUT_FILENAME, 'r', encoding='utf-8') as f:
                    result_data = json.load(f)
                processed_count = len(result_data)
                log(f"ğŸ”„ ê¸°ì¡´ ì‘ì—… íŒŒì¼ ë¡œë“œ: {processed_count}ê°œ ì™„ë£Œë¨", console=True)
            except:
                result_data = []

        real_start_idx = args.start + processed_count
        
        if real_start_idx >= end_idx:
            log("âœ… ì´ë¯¸ ì™„ë£Œëœ ì‘ì—…ì…ë‹ˆë‹¤.", console=True)
            return 0
        
        target_data = full_data[real_start_idx : end_idx]
        log(f"ğŸš€ ì‘ì—… ì‹œì‘: {len(target_data)}ê°œ ë¬¸ì œ ì²˜ë¦¬ ì¤‘...\n", console=True)
        
    except Exception as e:
        log(f"âŒ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}", console=True)
        return 1

    # ë©”ì¸ ë£¨í”„
    for i, item in enumerate(tqdm(target_data, desc="Processing", initial=processed_count, total=end_idx - args.start)):
        current_idx = real_start_idx + i
        
        try:
            problem = item['problem']
            prefix = item['prefix']
            cot_chunks = item['cot_chunks']
            gt_step_labels = item['gt_step_labels']
            valid_prefix_step_count = item['valid_prefix_step_count']
            
            updated_cot_chunks = cot_chunks.copy()
            
            log(f"\n\n{'='*30} Problem {current_idx} {'='*30}")
            
            for step_idx in range(valid_prefix_step_count):
                cot_prefix = get_cot_prefix_before_step(cot_chunks, step_idx)
                prompt = format_verification_prompt(problem, prefix, step_idx, cot_prefix)
                current_step_number = step_idx + 1
                
                print_full_prompt(prompt, current_step_number) # íŒŒì¼ì—ë§Œ ê¸°ë¡ë¨
                
                global prompt_to_states
                prompt_to_states = {}
                batch_args = [{'prompt': prompt, 'num_samples': N_SAMPLES_PER_STEP}]
                
                try:
                    _ = generate_step_verification.run_batch(batch_args)
                    if prompt not in prompt_to_states: raise KeyError("No Output")
                    states = prompt_to_states[prompt]
                    generated_verifications = [create_stop_sequence_after_boxed(s["verification_output"]) for s in states]
                except Exception as gen_err:
                    log(f"âŒ Generation Error: {gen_err}")
                    generated_verifications = []

                # ìƒì„¸ íŒŒì‹± ê²°ê³¼ ë¡œê·¸ ê¸°ë¡
                gt_label = gt_step_labels[step_idx]
                gt_numeric = 1 if gt_label == '+' else 0
                
                predicted_labels = []
                
                log(f"\n--- Step {current_step_number} Generation Results ({len(generated_verifications)} samples) ---")
                
                for s_i, gen_text in enumerate(generated_verifications):
                    step_verification, pred_label = extract_step_verification(gen_text, current_step_number)
                    predicted_labels.append(pred_label)
                    
                    # ìƒì„¸ ë‚´ìš©ì„ íŒŒì¼ì— ê¸°ë¡
                    log(f"\n[Sample {s_i+1}]")
                    log(f"Generated: {gen_text.strip()}")
                    label_str = 'Correct' if pred_label == 1 else 'Incorrect' if pred_label == 0 else 'FAIL(None)'
                    log(f"Extracted: {label_str} ({pred_label})")

                matches = sum(1 for pred in predicted_labels if pred == gt_numeric)
                confidence = matches / N_SAMPLES_PER_STEP
                
                # ìš”ì•½ ì •ë³´ ê¸°ë¡
                parsed_cnt = sum(1 for p in predicted_labels if p is not None)
                log(f"\n[Step {current_step_number} Summary]")
                log(f"GT: {gt_label} | Parsed: {parsed_cnt}/{N_SAMPLES_PER_STEP} | Match: {matches} | Conf: {confidence:.2f}")

                verification_count = 0
                for c_idx, chunk in enumerate(updated_cot_chunks):
                    if is_verification_chunk(chunk):
                        if verification_count == step_idx:
                            updated_cot_chunks[c_idx] = chunk + f"<confidence>{confidence:.2f}</confidence>"
                            break
                        verification_count += 1
            
            updated_item = item.copy()
            updated_item['cot_chunks'] = updated_cot_chunks
            updated_item['cot'] = ''.join(updated_cot_chunks)
            result_data.append(updated_item)
            
        except Exception as e:
            log(f"âš ï¸ Problem {current_idx} Error: {e}")
            log(traceback.format_exc())
            result_data.append(item)
            
        if (len(result_data) % args.save_interval == 0) or (i == len(target_data) - 1):
            log(f"ğŸ’¾ Checkpoint saved... ({len(result_data)} items)")
            try:
                with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:
                    json.dump(result_data, f, indent=2, ensure_ascii=False)
            except Exception as save_err:
                log(f"âŒ Save Error: {save_err}", console=True)

    log("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ.", console=True)
    return 0

if __name__ == "__main__":
    sys.exit(main())