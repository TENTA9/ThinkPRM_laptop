import os
import sys
import logging
from dataclasses import dataclass, field
from typing import Optional, List

import torch
import transformers
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    HfArgumentParser,
    TrainingArguments,
    Trainer,
    set_seed,
    BitsAndBytesConfig # ğŸ‘ˆ 4bit ì§€ì›ì„ ìœ„í•œ ëª¨ë“ˆ ì¶”ê°€
)
from peft import LoraConfig, get_peft_model, TaskType

# ì‚¬ìš©ìì˜ dataset í´ë” êµ¬ì¡°ì— ë§ì¶° import
from dataset.prm_dataset import LongThoughtCritiqueDataset

logger = logging.getLogger(__name__)

@dataclass
class ModelArguments:
    model_name_or_path: str = field(
        default="Qwen/Qwen2.5-1.5B-Instruct", 
        metadata={"help": "Path to pretrained model or model identifier from huggingface.co/models"}
    )
    use_lora: bool = field(default=True, metadata={"help": "Whether to use LoRA."})
    lora_r: int = field(default=32, metadata={"help": "LoRA r dimension."})
    lora_alpha: int = field(default=16, metadata={"help": "LoRA alpha."})
    lora_dropout: float = field(default=0.05, metadata={"help": "LoRA dropout."})
    lora_target_modules: List[str] = field(
        default_factory=lambda: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
        metadata={"help": "Target modules for LoRA"}
    )
    # ğŸ‘‡ ì´ ì¤„ì´ ìˆì–´ì•¼ --load_in_4bit ì˜µì…˜ì„ ì¸ì‹í•©ë‹ˆë‹¤!
    load_in_4bit: bool = field(default=False, metadata={"help": "Load model in 4-bit precision (QLoRA)."})

@dataclass
class DataArguments:
    data_dir: str = field(
        default=None, 
        metadata={"help": "Path to the folder containing training data json files."}
    )
    max_length: int = field(
        default=4096,
        metadata={"help": "Maximum sequence length."}
    )
    # Dataset Class ì„¤ì •
    max_cots_per_solution: int = field(default=1, metadata={"help": "Max CoTs per solution."})
    match_all_step_labels: bool = field(default=True, metadata={"help": "Filter based on all step labels."})
    filter_based_on_length: bool = field(default=True, metadata={"help": "Filter out too long sequences."})
    balance_data: bool = field(default=False, metadata={"help": "Balance correct/incorrect examples."})
    add_think_token: bool = field(default=True, metadata={"help": "Add <think> token explicitly."})
    
    # í˜¸í™˜ì„± ìœ ì§€ìš© ë”ë¯¸ ì†ì„±ë“¤
    train_with_gold_solutions: bool = False
    add_partial_prefixes: bool = False
    single_label: bool = False 
    direct_prm: bool = False
    cot_incorrect_only: bool = False

def main():
    parser = HfArgumentParser((ModelArguments, DataArguments, TrainingArguments))
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()

    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
        datefmt="%m/%d/%Y %H:%M:%S",
        handlers=[logging.StreamHandler(sys.stdout)],
    )
    set_seed(training_args.seed)

    # 1. í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(
        model_args.model_name_or_path,
        model_max_length=data_args.max_length,
        padding_side="right",
        use_fast=True,
        trust_remote_code=True
    )
    
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
        
    if data_args.add_think_token and "<think>" not in tokenizer.vocab:
        special_tokens_dict = {'additional_special_tokens': ['<think>', '</think>']}
        tokenizer.add_special_tokens(special_tokens_dict)

    # 2. ë°ì´í„°ì…‹ ì¤€ë¹„
    logger.info("Loading dataset...")
    train_dataset = LongThoughtCritiqueDataset(
        data_path=data_args.data_dir,
        tokenizer=tokenizer,
        config=data_args, 
        split='train'
    )

    # 3. ëª¨ë¸ ë¡œë“œ
    logger.info("Loading model...")
    
    # QLoRA ì„¤ì • (4-bit ì‚¬ìš© ì‹œì—ë§Œ ì ìš©ë¨)
    quantization_config = None
    if model_args.load_in_4bit:
        quantization_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_compute_dtype=torch.bfloat16, 
            bnb_4bit_use_double_quant=True,
            bnb_4bit_quant_type="nf4"
        )
        logger.info("ğŸš€ Using QLoRA (4-bit quantization)")

    model = AutoModelForCausalLM.from_pretrained(
        model_args.model_name_or_path,
        torch_dtype=torch.bfloat16,
        device_map="auto",
        trust_remote_code=True,
        quantization_config=quantization_config, # ì„¤ì • ì ìš© (Noneì´ë©´ ë¬´ì‹œë¨)
        use_cache=False if training_args.gradient_checkpointing else True
    )

    model.resize_token_embeddings(len(tokenizer))
    
    if training_args.gradient_checkpointing:
        model.enable_input_require_grads()

    # 4. LoRA ì„¤ì • (ì‚¬ìš© ì•ˆ í•˜ë©´ íŒ¨ìŠ¤)
    if model_args.use_lora:
        logger.info("Applying LoRA...")
        peft_config = LoraConfig(
            task_type=TaskType.CAUSAL_LM,
            inference_mode=False,
            r=model_args.lora_r,
            lora_alpha=model_args.lora_alpha,
            lora_dropout=model_args.lora_dropout,
            target_modules=model_args.lora_target_modules,
            bias="none",
        )
        model = get_peft_model(model, peft_config)
        model.print_trainable_parameters()

    # 5. Trainer ì„¤ì •
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        tokenizer=tokenizer,
        data_collator=train_dataset.collate_fn,
    )

    # 6. í•™ìŠµ ì‹œì‘
    logger.info("Starting training...")
    trainer.train()

    # 7. ëª¨ë¸ ì €ì¥
    logger.info("Saving model...")
    trainer.save_model(training_args.output_dir)
    tokenizer.save_pretrained(training_args.output_dir)

if __name__ == "__main__":
    main()